---
permalink: /
title: "Yuzhi Zhao"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Researcher, ByteDance

Shenzhen, China

**Short Bio**
======

I received the Ph.D. degree from [Department of Electronic Engineering](https://www.ee.cityu.edu.hk/), [City University of Hong Kong](https://www.cityu.edu.hk/) in February 2023 and the B.Eng. degree from [School of Electronic and Information Engineering](http://ei.hust.edu.cn/) ([Qiming College](http://qiming.hust.edu.cn/)), [Huazhong University of Science and Technology](https://www.hust.edu.cn/) in June 2018. I have broad interests in AI applications, including low-level vision and computational photography, generative models (e.g., GAN and diffusion model). Recently, I focuses on applications of Multimodal Large Language Model (MLLM), e.g., AI Agent. I have more than 40 published papers and 11 of which are as the first or corresponding author (CCF A or CAAI A rank). My citation is more than 1500 and the most cited first-authored paper gets 225 cites.

**Working Experiences**
======

Now I am a researcher at ByteDance Research. I focus GUI Agent and MLLM and their applications in testing area.

Previously, I was with 2012 Labs, Huawei Hong Kong Research Center, working on MLLM and AI Agent projects. Specifically, I and my group developed the multimodal content moderation system and GUI Test Agent for HarmonyOS. My research results have been successfully applied in Huawei's product lines.

I was a student researcher at [AI Imaging Group, SenseTime](https://www.sensetime.com/cn), working on computational photography research and projects. Specifically, I developed two joint deblurring and denoising systems on RGB images and RAW images, respectively. I was also a student researcher at [Lightspeed and Quantum Studios, Tencent IEG](https://www.lightspeed-studios.com/), working on AIGC projects (e.g., stable diffusion).

<font color='red'>We are hiring! Please email me if you are interested in an internship / research engineer position (MLLM research or projects, GUI Agents, base: Shenzhen or Beijing).</font> 

**Selected Publication**
======

<sup>*</sup>: corresponding author

- LLM/MLLM Training (like RLVR or continual training)

Hieu Trung Nguyen, Bao Nguyen, Wenao Ma, **Yuzhi Zhao**, Ruifeng She, Viet Anh Nguyen. <font color='Navy'>Adaptive Rollout Allocation for Online Reinforcement Learning with Verifiable Rewards</font>. ICLR, 2026 ([PDF](../files/2026-Adaptive-Rollout-Allocation-for-Online-Reinforcement-Learning-with-Verifiable-Rewards.pdf)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://openreview.net/forum?id=Z5sWYACAop&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2026%2FConference%2FAuthors%23your-submissions)))

Jinpeng Chen, Runmin Cong, **Yuzhi Zhao<sup>*</sup>**, Hongzheng Yang, Guangneng Hu, Horace Ip, Sam Kwong. <font color='Navy'>SEFE: Superficial and Essential Forgetting Eliminator for Multimodal Continual Instruction Tuning</font>. ICML, 2025 ([PDF](../files/2025-SEFE-Superficial-and-Essential-Forgetting-Eliminator-for-Multimodal-Continual-Instruction-Tuning.pdf)) (<img src="../images/github_icon.png" width="20" height="20" hspace="5">[Code](https://github.com/jinpeng0528/SEFE)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://arxiv.org/abs/2505.02486v1))

Donglai Xu, Hongzheng Yang, **Yuzhi Zhao<sup>*</sup>**, Pingping Zhang, Jinpeng Chen, Wenao Ma, Zhijian Hou, Mengyang Wu, Xiaolei Li, Senkang Hu, Ziyi Guan, Jason Chun Lok Li, Lai-Man Po. <font color='Navy'>From Exploration to Exploitation: A Two-Stage Entropy RLVR Approach for Noise-Tolerant MLLM Training</font>. Preprint, 2025 (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://arxiv.org/abs/2511.07738))

- AI Agent, Vertical LLM/MLLM

Ziyi Guan, Jason Chun Lok Li, Zhijian Hou, Pingping Zhang, Donglai Xu, Pengfei Xian, Mengyang Wu, Jinpeng Chen, Wenao Ma, **Yuzhi Zhao<sup>*</sup>**, Shengchao Qin, Graziano Chesi, Ngai Wong. <font color='Navy'>KG-RAG: Enhancing App Decision-Making via Knowledge Graph-Driven Retrieval-Augmented Generation</font>. EMNLP, 2025 ([PDF](../files/2025-KG-RAG-Enhancing-GUI-Agent-Decision-Making-via-Knowledge-Graph-Driven-Retrieval-Augmented-Generation.pdf)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://arxiv.org/abs/2509.00366))

Mengyang Wu, **Yuzhi Zhao<sup>*</sup>**, Jialun Cao, Mingjie Xu, Zhongming Jiang, Xuehui Wang, Qinbin Li, Guangneng Hu, Shengchao Qin, Chi-Wing Fu. <font color='Navy'>ICM-Assistant: Instruction-tuning Multimodal Large Language Models for Rule-based Explainable Image Content Moderation</font>. AAAI, 2025 ([PDF](../files/2025-ICM-Assistant-Instruction-tuning-Multimodal-Large-Language-Models-for-Rule-based-Explainable-Image-Content-Moderation.pdf)) (<img src="../images/github_icon.png" width="20" height="20" hspace="5">[Code](https://github.com/zhaoyuzhi/ICM-Assistant)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://arxiv.org/abs/2412.18216))

Mingjie Xu, Mengyang Wu, **Yuzhi Zhao<sup>*</sup>**, Jason Chun Lok Li, Weifeng Ou. <font color='Navy'>LLaVA-SpaceSGG: Visual Instruct Tuning for Open-vocabulary Scene Graph Generation with Enhanced Spatial Relations</font>. WACV, 2025 ([PDF](../files/2025-LLaVA-SpaceSGG-Visual-Instruct-Tuning-for-Open-vocabulary-Scene-Graph.pdf)) (<img src="../images/github_icon.png" width="20" height="20" hspace="5">[Code](https://github.com/Endlinc/LLaVA-SpaceSGG)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://arxiv.org/abs/2412.06322))

- LLM/MLLM Benchmarks

Mingjie Xu, Jinpeng Chen, **Yuzhi Zhao<sup>*</sup>**, Jason Chun Lok Li, Yue Qiu, Zekang Du, Mengyang Wu, Pingping Zhang, Kun Li, Hongzheng Yang, Wenao Ma, Jiaheng Wei, Qinbin Li, Kangcheng Liu, Wenqiang Lei. <font color='Navy'>VP-Bench: A Comprehensive Benchmark for Visual Prompting in Multimodal Large Language Models</font>. AAAI, 2026 ([PDF](../files/2026-VP-Bench-A-Comprehensive-Benchmark-for-Visual-Prompting-in-Multimodal-Large-Language-Models.pdf)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://arxiv.org/abs/2511.11438))

Li Kun, Lai Man Po, Hongzheng Yang, Xuyuan Xu, Kangcheng Liu, **Yuzhi Zhao<sup>*</sup>**. <font color='Navy'>AesBiasBench: Evaluating Bias and Alignment in Multimodal Language Models for Personalized Image Aesthetic Assessment</font>. EMNLP, 2025 ([PDF](../files/2025-AesBiasBench-Evaluating-Bias-and-Alignment-in-Multimodal-Language-Models-for-Personalized-Image-Aesthetic-Assessment.pdf)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://arxiv.org/abs/2509.11620))

- Low-level Vision and computational photography

**Yuzhi Zhao<sup>*</sup>**, Lai-Man Po, Xin Ye, Qiong Yan, Yongzhe Xu. <font color='Navy'>Modeling Dual-Exposure Quad-Bayer Patterns for Joint Denoising and Deblurring</font>. IEEE Transactions on Image Processing, 2024 ([PDF](../files/2024-Modeling-Dual-Exposure-Quad-Bayer-Patterns-for-Joint-Denoising-and-Deblurring.pdf)) (<img src="../images/github_icon.png" width="20" height="20" hspace="5">[Code](https://github.com/zhaoyuzhi/QRNet)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://arxiv.org/abs/2412.07256))

**Yuzhi Zhao<sup>*</sup>**, Lai-Man Po, Kangcheng Liu, Xuehui Wang, Wing-Yin Yu. <font color='Navy'>SVCNet: Real-time Scribble-based Video Colorization with Pyramid Networks</font>. IEEE Transactions on Image Processing, 2023 ([PDF](../files/2023-SVCNet-Scribble-Based-Video-Colorization-Network-With-Temporal-Aggregation.pdf)) (<img src="../images/github_icon.png" width="20" height="20" hspace="5">[Code](https://github.com/zhaoyuzhi/SVCNet)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://ieeexplore.ieee.org/document/10198230))

**Yuzhi Zhao<sup>*</sup>**, Lai-Man Po, Tingyu Lin, Qiong Yan, Wei Liu, Pengfei Xian. <font color='Navy'>HSGAN: Hyperspectral Reconstruction from RGB Images with Generative Adversarial Network</font>. IEEE Transactions on Neural Networks and Learning Systems, 2023 ([PDF](../files/2023-HSGAN-Hyperspectral-Reconstruction-From-RGB-Images-With-Generative-Adversarial-Network.pdf)) (<img src="../images/github_icon.png" width="20" height="20" hspace="5">[Code](https://github.com/zhaoyuzhi/HSGAN)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://ieeexplore.ieee.org/document/10214426))

**Yuzhi Zhao<sup>*</sup>**, Yongzhe Xu, Qiong Yan, Dingdong Yang, Xuehui Wang, and Lai-Man Po. <font color='Navy'>D2HNet: Joint Denoising and Deblurring with Hierarchical Network for Robust Night Image Restoration</font>. ECCV, 2022 ([PDF](../files/2022-D2HNet-Joint-Denoising-and-Deblurring-with-Hierarchical-Network-for-Robust-Night-Image-Restoration.pdf)) (<img src="../images/github_icon.png" width="20" height="20" hspace="5">[Code/Dataset](https://github.com/zhaoyuzhi/D2HNet)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://arxiv.org/pdf/2207.03294.pdf))

**Yuzhi Zhao<sup>*</sup>**, Lai-Man Po, Xuehui Wang, Qiong Yan, Wei Shen, et al. <font color='Navy'>ChildPredictor: A Child Face Prediction Framework with Disentangled Learning</font>. IEEE Transactions on Multimedia, 2022 ([PDF](../files/2022-ChildPredictor-A-Child-Face-Prediction-Framework-with-Disentangled-Learning.pdf)) (<img src="../images/github_icon.png" width="20" height="20" hspace="5">[Code/Dataset](https://github.com/zhaoyuzhi/ChildPredictor)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://ieeexplore.ieee.org/document/9749880))

**Yuzhi Zhao<sup>*</sup>**, Lai-Man Po, Wing-Yin Yu, YAU Rehman, Mengyang Liu, Yujia Zhang, Weifeng Ou. <font color='Navy'>VCGAN: Video Colorization with Hybrid Generative Adversarial Network</font>. IEEE Transactions on Multimedia, 2022 ([PDF](../files/2022-VCGAN-Video-Colorization-with-Hybrid-Generative-Adversarial-Network.pdf)) (<img src="../images/github_icon.png" width="20" height="20" hspace="5">[Code](https://github.com/zhaoyuzhi/VCGAN)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://ieeexplore.ieee.org/abstract/document/9721653))

**Yuzhi Zhao<sup>*</sup>**, Lai-Man Po, Kwok-Wai Cheung, Wing-Yin Yu, YAU Rehman. <font color='Navy'>SCGAN: Saliency Map-guided Colorization with Generative Adversarial Network</font>. IEEE Transactions on Circuits and Systems for Video Technology, 2020 ([PDF](../files/2020-SCGAN-Saliency-Map-guided-Colorization-with-Generative-Adversarial-Network.pdf)) (<img src="../images/github_icon.png" width="20" height="20" hspace="5">[Code](https://github.com/zhaoyuzhi/Semantic-Colorization-GAN)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9257445))

- Generative models

Wing-Yin Yu, Lai-Man Po, Ray C.C. Cheung, **Yuzhi Zhao**, Yu Xue, Kun Li. <font color='Navy'>Bidirectionally Deformable Motion Modulation For Video-based Human Pose Transfer</font>. ICCV, 2023 ([PDF](../files/2023-Bidirectionally-Deformable-Motion-Modulation-For-Video-based-Human-Pose-Transfer.pdf)) (<img src="../images/github_icon.png" width="20" height="20" hspace="5">[Code](https://github.com/rocketappslab/bdmm)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://arxiv.org/pdf/2307.07754.pdf))

Wing-Yin Yu, Lai-Man Po, Jingjing Xiong, **Yuzhi Zhao**, Pengfei Xian. <font color='Navy'>ShaTure: Shape and Texture Deformation for Human Pose and Attribute Transfer</font>. IEEE Transactions on Image Processing, 2022 ([PDF](../files/2022-ShaTure-Shape-and-Texture-Deformation-for-Human-Pose-and-Attribute-Transfer.pdf)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://ieeexplore.ieee.org/document/9733197))

- Representation learning

Xuehui Wang, Chongjie Si, Xue Yang, **Yuzhi Zhao**, Wenhai Wang, Xiaokang Yang, Wei Shen. <font color='Navy'>OPMapper: Enhancing Open-Vocabulary Semantic Segmentation with Multi-Guidance Information</font>. NeurIPS, 2025 ([PDF](../files/2025-OPMapper-Enhancing-Open-Vocabulary-Semantic-Segmentation-with-Multi-Guidance-Information.pdf)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://openreview.net/forum?id=UjSBOwKZ02&referrer=%5Bthe%20profile%20of%20Yuzhi%20Zhao%5D(%2Fprofile%3Fid%3D~Yuzhi_Zhao1)))

Kangcheng Liu, **Yuzhi Zhao**, Qiang Nie, Zhi Gao, and Ben M. Chen. <font color='Navy'>Weakly Supervised 3D Scene Segmentation with Region-Level Boundary Awareness and Instance Discrimination</font>. ECCV, 2022 ([PDF](../files/2022-Weakly-Supervised-3D-Scene-Segmentation-with-Region-Level-Boundary-Awareness-and-Instance-Discrimination.pdf)) (<img src="../images/github_icon.png" width="20" height="20" hspace="5">[Code](https://github.com/Smart-Robotics-Scientist/Weakly-Supervised-3D)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136880036.pdf))

Yujia Zhang, Lai-Man Po, Xuyuan Xu, Mengyang Liu, Yexin Wang, Weifeng Ou, **Yuzhi Zhao**, Wing-Yin Yu. <font color='Navy'>Contrastive Spatio-Temporal Pretext Learning for Self-supervised Video Representation</font>. AAAI, 2022 ([PDF](../files/2022-Contrastive-Spatio-Temporal-Pretext-Learning-for-Self-supervised-Video-Representation.pdf)) (<img src="../images/github_icon.png" width="20" height="20" hspace="5">[Code](https://github.com/KT27-A/CSTP)) (<img src="../images/pdf_icon.png" width="20" height="20" hspace="5">[URL](https://ojs.aaai.org/index.php/AAAI/article/view/20248))
